{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **Cassava leaf disease classification: ResNext Model with Test Time Augmentation!**"]},{"cell_type":"markdown","metadata":{},"source":["*We started by importing all the necessary libraris needed for this implementation, and we'll try as much as we can to comment every line of code!*"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install ttach # Intalling the test time augmentation package"]},{"cell_type":"code","execution_count":4,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-19T09:07:49.252724Z","iopub.status.busy":"2024-05-19T09:07:49.252330Z","iopub.status.idle":"2024-05-19T09:07:55.545913Z","shell.execute_reply":"2024-05-19T09:07:55.545083Z","shell.execute_reply.started":"2024-05-19T09:07:49.252690Z"},"papermill":{"duration":1.438614,"end_time":"2021-03-29T11:50:48.533762","exception":false,"start_time":"2021-03-29T11:50:47.095148","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# We started by importing all the necessary libraris needed for this implementation.\n","import os # functionalities for interacting with the operating system (reading files etc..).\n","import sys # import system modules\n","import glob # search for files that match specific patterns\n","import torch # pytorch package, which contains other utilities for deep learning.\n","import torchvision\n","import pandas as pd\n","from tqdm import tqdm\n","from torchvision.models import alexnet\n","\n","import numpy    as np\n","import datetime as dt\n","import torch.nn as nn\n","import ttach as tta # augmenting test time data and averaging the predictions\n","\n","import torch.nn.functional as F\n","import matplotlib.pyplot   as plt\n","\n","from PIL               import Image\n","from torch.utils.data  import Dataset\n","from torch.autograd    import Variable\n","from torch.optim       import lr_scheduler\n","\n","from torch.utils.data  import Dataset, DataLoader\n","from torch.utils.data.sampler import SubsetRandomSampler\n","from torchvision       import transforms, datasets, models\n","from os                import listdir, makedirs, getcwd, remove\n","from os.path           import isfile, join, abspath, exists, isdir, expanduser\n","import gc\n","# torch.cuda.empty_cache()\n","gc.collect()\n","import os\n","os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n","\n","\n","import warnings \n","warnings.filterwarnings('ignore')\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{},"source":["### **Loading the dataset**"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T09:30:54.512400Z","iopub.status.busy":"2024-05-19T09:30:54.511996Z","iopub.status.idle":"2024-05-19T09:30:54.517557Z","shell.execute_reply":"2024-05-19T09:30:54.516535Z","shell.execute_reply.started":"2024-05-19T09:30:54.512371Z"},"papermill":{"duration":0.021142,"end_time":"2021-03-29T11:50:48.566314","exception":false,"start_time":"2021-03-29T11:50:48.545172","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["data_path = \"/kaggle/input/ammi-2024-computer-vision/\"\n","train_path = join(data_path, \"train/train\")\n","test_path = join(data_path,\"test/test\")\n","extraimage_path = join(data_path, \"extraimages/extraimages\")\n","print(\"Successfully loaded the datset!\")"]},{"cell_type":"markdown","metadata":{},"source":["### **Device configuration**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{},"source":["### **Transforming the dataset**\n","\n","*Transformin the dataset is essential for augmentation.*"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T09:30:54.869565Z","iopub.status.busy":"2024-05-19T09:30:54.868625Z","iopub.status.idle":"2024-05-19T09:30:54.877999Z","shell.execute_reply":"2024-05-19T09:30:54.876630Z","shell.execute_reply.started":"2024-05-19T09:30:54.869526Z"},"trusted":true},"outputs":[],"source":["# Transformations for both the training and testing data\n","mean=[0.485, 0.456, 0.406] # mean and standard deviation for RGB channels.\n","std=[0.229, 0.224, 0.225]\n","\n","# randomly crop all the training images, convert them to a tesnor and normalize them.\n","train_transforms  = transforms.Compose([\n","    transforms.Resize((580,580)),\n","    #transforms.CenterCrop(448),\n","    transforms.RandomHorizontalFlip(p=0.5),\n","    transforms.RandomVerticalFlip(p=0.5),\n","    transforms.RandomRotation(degrees = 30),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    \n","])\n","\n","\n","test_transforms = transforms.Compose([ transforms.Resize((580,580)),\n","                                       #transforms.Resize(255),\n","                                       #transforms.CenterCrop(448),\n","                                       transforms.ToTensor(),\n","                                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### **Implementing the datasset class**\n","\n","*Easier to access and handle images during training*"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T09:30:55.359297Z","iopub.status.busy":"2024-05-19T09:30:55.358318Z","iopub.status.idle":"2024-05-19T09:30:55.369151Z","shell.execute_reply":"2024-05-19T09:30:55.368105Z","shell.execute_reply.started":"2024-05-19T09:30:55.359260Z"},"papermill":{"duration":0.02374,"end_time":"2021-03-29T11:50:48.633742","exception":false,"start_time":"2021-03-29T11:50:48.610002","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class CassavaDataset(Dataset):\n","    def __init__(self, path, transform=None):\n","        self.classes = os.listdir(path)\n","        self.path = [f\"{path}/{className}\" for className in self.classes]\n","        self.file_list = [glob.glob(f\"{x}/*\") for x in self.path]\n","        self.transform = transform\n","\n","        files = []\n","        for i, className in enumerate(self.classes):\n","            for fileName in self.file_list[i]:\n","                files.append([i, className, fileName])\n","        self.file_list = files\n","        files = None\n","\n","    def __len__(self):\n","        return len(self.file_list)\n","\n","    def __getitem__(self, idx):\n","        fileName = self.file_list[idx][2]\n","        classCategory = self.file_list[idx][0]\n","        im = Image.open(fileName)\n","        if self.transform:\n","            im = self.transform(im)\n","            \n","        return im.view(3, 580, 580), classCategory"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T09:30:55.707859Z","iopub.status.busy":"2024-05-19T09:30:55.707248Z","iopub.status.idle":"2024-05-19T09:30:56.528381Z","shell.execute_reply":"2024-05-19T09:30:56.527495Z","shell.execute_reply.started":"2024-05-19T09:30:55.707829Z"},"papermill":{"duration":0.614629,"end_time":"2021-03-29T11:50:49.259763","exception":false,"start_time":"2021-03-29T11:50:48.645134","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["train_data = CassavaDataset(train_path, transform=train_transforms)\n","test_data = CassavaDataset(test_path, transform=test_transforms)"]},{"cell_type":"markdown","metadata":{},"source":["### **Creating data indices for training and validation**"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T09:30:56.530966Z","iopub.status.busy":"2024-05-19T09:30:56.530276Z","iopub.status.idle":"2024-05-19T09:30:56.537782Z","shell.execute_reply":"2024-05-19T09:30:56.536909Z","shell.execute_reply.started":"2024-05-19T09:30:56.530910Z"},"papermill":{"duration":0.022198,"end_time":"2021-03-29T11:50:49.293623","exception":false,"start_time":"2021-03-29T11:50:49.271425","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["validation_split = 0.1\n","shuffle_dataset = True\n","random_seed= 42\n","\n","dataset_size = len(train_data)\n","indices = list(range(dataset_size))\n","split = int(np.floor(validation_split * dataset_size))\n","\n","if shuffle_dataset :\n","    np.random.seed(random_seed)\n","    np.random.shuffle(indices)\n","\n","train_indices, val_indices = indices[split:], indices[:split]"]},{"cell_type":"markdown","metadata":{},"source":["### **Preparing the data samplers and loaders**"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T09:30:58.028194Z","iopub.status.busy":"2024-05-19T09:30:58.027373Z","iopub.status.idle":"2024-05-19T09:30:58.034731Z","shell.execute_reply":"2024-05-19T09:30:58.033697Z","shell.execute_reply.started":"2024-05-19T09:30:58.028155Z"},"papermill":{"duration":0.02193,"end_time":"2021-03-29T11:50:49.327221","exception":false,"start_time":"2021-03-29T11:50:49.305291","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["train_sampler = SubsetRandomSampler(train_indices)\n","valid_sampler = SubsetRandomSampler(val_indices)\n","\n","train_loader = torch.utils.data.DataLoader(train_data, batch_size=8,\n","                                             sampler=train_sampler)\n","valid_loader = torch.utils.data.DataLoader(train_data, batch_size=8,\n","                                             sampler=valid_sampler)\n","test_loader = torch.utils.data.DataLoader(test_data, batch_size=8)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T09:31:16.758422Z","iopub.status.busy":"2024-05-19T09:31:16.758030Z","iopub.status.idle":"2024-05-19T09:31:18.205293Z","shell.execute_reply":"2024-05-19T09:31:18.204427Z","shell.execute_reply.started":"2024-05-19T09:31:16.758391Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNeXt50_32X4D_Weights.IMAGENET1K_V1`. You can also use `weights=ResNeXt50_32X4D_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /root/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth\n","100%|██████████| 95.8M/95.8M [00:00<00:00, 144MB/s] \n"]}],"source":["torch.manual_seed(random_seed)  # Fix the random seed\n","\n","model = torchvision.models.resnext50_32x4d(pretrained=True) # Loading the resnext50_32x4d pretrained model.\n","\n","# Set the final linear layer to the number of classes.\n","num_ftrs = model.fc.in_features\n","model.fc = nn.Linear(num_ftrs, 5)\n","model = model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","hypergrad_lr = 1e-9 # hypergradient learning rate.\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=3e-3)\n","hypergrad_optimizer = torch.optim.Adam(model.parameters(), lr=hypergrad_lr)\n"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T09:31:32.809634Z","iopub.status.busy":"2024-05-19T09:31:32.809259Z","iopub.status.idle":"2024-05-19T09:31:32.824459Z","shell.execute_reply":"2024-05-19T09:31:32.823451Z","shell.execute_reply.started":"2024-05-19T09:31:32.809597Z"},"trusted":true},"outputs":[],"source":["# Define the path to the folder containing the subfolders\n","path = train_path\n","\n","# Get the list of subfolders\n","subfolders = [f.path for f in os.scandir(path) if f.is_dir()]\n","\n","# Create a list to store the number of images in each subfolder\n","num_images = []\n","\n","# Iterate over the subfolders and count the number of images\n","for subfolder in subfolders:\n","    num_images.append(len(os.listdir(subfolder)))\n","\n","# Compute class weights\n","class_counts = num_images  # Number of samples per class\n","total_samples = sum(class_counts)\n","class_weights = [total_samples / (len(class_counts) * count) for count in class_counts]\n","class_weights = torch.FloatTensor(class_weights).to(device)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T09:31:32.826950Z","iopub.status.busy":"2024-05-19T09:31:32.826580Z","iopub.status.idle":"2024-05-19T09:31:39.580400Z","shell.execute_reply":"2024-05-19T09:31:39.579406Z","shell.execute_reply.started":"2024-05-19T09:31:32.826910Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNeXt101_64X4D_Weights.IMAGENET1K_V1`. You can also use `weights=ResNeXt101_64X4D_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnext101_64x4d-173b62eb.pth\" to /root/.cache/torch/hub/checkpoints/resnext101_64x4d-173b62eb.pth\n","100%|██████████| 319M/319M [00:04<00:00, 76.0MB/s] \n"]}],"source":["num_classes = 5\n","num_epochs = 10\n","learning_rate = 1e-4\n","hypergrad_lr = 1e-9\n","\n","model1 = torchvision.models.resnext101_64x4d(pretrained=True) # Loading the resnext101_64x4d pretrained model\n","model1.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","num_features = model1.fc.in_features\n","model1.fc = nn.Linear(num_features, num_classes)\n","\n","criterion = nn.CrossEntropyLoss(weight=class_weights)\n","\n","optimizer = torch.optim.Adam(model1.parameters(), lr=learning_rate)\n","hypergrad_optimizer = torch.optim.Adam(model1.parameters(), lr=hypergrad_lr)"]},{"cell_type":"markdown","metadata":{},"source":["### **The train function**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train(model, criterion, data_loader, valid_loader, optimizer, num_epochs):\n","    # Move model to the device (CPU or GPU).\n","    model = model.to(device)\n","    \n","    # Exponential moving average of the loss.\n","    ema_loss = None\n","    best_acc = 0\n","\n","    # Lists to store losses and accuracies.\n","    losses = []\n","    training_accuracies = []\n","    validation_accuracies = []\n","\n","    print('----- Training Loop -----')\n","    \n","    # Loop over epochs.\n","    for epoch in range(num_epochs):\n","        # Make sure model is in training mode.\n","        model.train()\n","        correct = 0\n","        \n","        # Loop over data.\n","        for batch_idx, (features, target) in enumerate(data_loader):\n","            torch.cuda.empty_cache()\n","            \n","            # Forward pass.\n","            output = model(features.to(device))\n","            loss = criterion(output.to(device), target.to(device))\n","            \n","            # Backward pass.\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            \n","            # Compute the training accuracy\n","            with torch.no_grad():\n","                pred = output.argmax(dim=1, keepdim=True)\n","                \n","                # Count number of correct predictions.\n","                correct += pred.cpu().eq(target.view_as(pred)).sum().item()\n","            \n","            # Exponential moving average of the loss.\n","            if ema_loss is None:\n","                ema_loss = loss.item()\n","            else:\n","                ema_loss += (loss.item() - ema_loss) * 0.01\n","        \n","        # Compute the training accuracy.\n","        train_score = 100. * correct / len(data_loader.sampler)\n","        \n","        # Compute the validation accuracy.\n","        valid_score = test(model, valid_loader)\n","        \n","        # Store the losses and accuracies.\n","        losses.append(ema_loss)\n","        training_accuracies.append(train_score)\n","        validation_accuracies.append(valid_score)\n","        \n","        # Save the best model.\n","        if valid_score > best_acc:\n","            best_acc = valid_score\n","            torch.save(model, 'get_resnext101_weighted.pth')\n","        \n","        # Print out progress at the end of epoch.\n","        print(f'Epoch: {epoch} \\tLoss: {ema_loss:.12f} \\tTraining Accuracy: {train_score:.12f} \\tValidation Accuracy: {valid_score:.12f}')\n","\n","    return losses, training_accuracies, validation_accuracies\n"]},{"cell_type":"markdown","metadata":{},"source":["### **The test function**"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T09:31:39.582001Z","iopub.status.busy":"2024-05-19T09:31:39.581650Z","iopub.status.idle":"2024-05-19T09:31:39.590535Z","shell.execute_reply":"2024-05-19T09:31:39.589347Z","shell.execute_reply.started":"2024-05-19T09:31:39.581973Z"},"trusted":true},"outputs":[],"source":["def test(model, data_loader):\n","    # Make sure the model is in evaluation mode.\n","    model.eval()\n","    correct = 0\n","    print('----- Model Evaluation -----')\n","    \n","    # We do not need to maintain intermediate activations while testing.\n","    with torch.no_grad():\n","        # Loop over test data.\n","        for features, target in data_loader:\n","            # Forward pass.\n","            output = model(features.to(device))\n","            \n","            # Get the label corresponding to the highest predicted probability.\n","            pred = output.argmax(dim=1, keepdim=True)\n","            \n","            # Count number of correct predictions.\n","            correct += pred.cpu().eq(target.view_as(pred)).sum().item()\n","    \n","    # Print test accuracy.\n","    percent = 100. * correct / len(valid_sampler)\n","    print(f'Test accuracy: {correct} / {len(valid_sampler)} ({percent:.0f}%)')\n","    \n","    # torch.save(model.state_dict(), 'model.ckpt')\n","    return percent\n"]},{"cell_type":"markdown","metadata":{},"source":["### **Start training**"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T23:07:31.876003Z","iopub.status.busy":"2024-05-18T23:07:31.875618Z","iopub.status.idle":"2024-05-19T03:16:25.204670Z","shell.execute_reply":"2024-05-19T03:16:25.203703Z","shell.execute_reply.started":"2024-05-18T23:07:31.875974Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Training Loop -----\n","----- Model Evaluation -----\n","Test accuracy: 473 / 565 (84%)\n","Epoch: 0 \tLoss: 0.578116055279 \tTraining Accuracy: 77.843252799057 \t Validation Accuracy: 83.716814159292\n","----- Model Evaluation -----\n","Test accuracy: 510 / 565 (90%)\n","Epoch: 1 \tLoss: 0.446727400861 \tTraining Accuracy: 85.955607935573 \t Validation Accuracy: 90.265486725664\n","----- Model Evaluation -----\n","Test accuracy: 512 / 565 (91%)\n","Epoch: 2 \tLoss: 0.344238200770 \tTraining Accuracy: 87.762718522884 \t Validation Accuracy: 90.619469026549\n","----- Model Evaluation -----\n","Test accuracy: 508 / 565 (90%)\n","Epoch: 3 \tLoss: 0.310996923967 \tTraining Accuracy: 89.668041642114 \t Validation Accuracy: 89.911504424779\n","----- Model Evaluation -----\n","Test accuracy: 505 / 565 (89%)\n","Epoch: 4 \tLoss: 0.299683268496 \tTraining Accuracy: 91.376939697505 \t Validation Accuracy: 89.380530973451\n","----- Model Evaluation -----\n","Test accuracy: 509 / 565 (90%)\n","Epoch: 5 \tLoss: 0.243495238712 \tTraining Accuracy: 92.614417599686 \t Validation Accuracy: 90.088495575221\n","----- Model Evaluation -----\n","Test accuracy: 506 / 565 (90%)\n","Epoch: 6 \tLoss: 0.195162089454 \tTraining Accuracy: 93.360832842271 \t Validation Accuracy: 89.557522123894\n","----- Model Evaluation -----\n","Test accuracy: 507 / 565 (90%)\n","Epoch: 7 \tLoss: 0.159881586481 \tTraining Accuracy: 93.380475348654 \t Validation Accuracy: 89.734513274336\n","----- Model Evaluation -----\n","Test accuracy: 484 / 565 (86%)\n","Epoch: 8 \tLoss: 0.164418969056 \tTraining Accuracy: 95.148300923198 \t Validation Accuracy: 85.663716814159\n","----- Model Evaluation -----\n","Test accuracy: 505 / 565 (89%)\n","Epoch: 9 \tLoss: 0.114828447428 \tTraining Accuracy: 95.325083480652 \t Validation Accuracy: 89.380530973451\n"]}],"source":["num_epochs = 10 # set number of epochs for training\n","losses, training_accuracies, validation_accuracies = train(model1, criterion, train_loader, valid_loader, optimizer, num_epochs)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T03:19:40.126112Z","iopub.status.busy":"2024-05-19T03:19:40.125419Z","iopub.status.idle":"2024-05-19T03:20:36.156742Z","shell.execute_reply":"2024-05-19T03:20:36.155814Z","shell.execute_reply.started":"2024-05-19T03:19:40.126075Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Model Evaluation -----\n","Test accuracy: 498 / 565 (88%)\n"]},{"data":{"text/plain":["88.14159292035399"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# validating the performance of model1\n","test(model1, valid_loader)"]},{"cell_type":"markdown","metadata":{},"source":["### **Test Time Augmentation with Differenet Transformations**"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T03:23:00.922555Z","iopub.status.busy":"2024-05-19T03:23:00.921694Z","iopub.status.idle":"2024-05-19T03:23:00.927202Z","shell.execute_reply":"2024-05-19T03:23:00.926153Z","shell.execute_reply.started":"2024-05-19T03:23:00.922487Z"},"trusted":true},"outputs":[],"source":["tta_model = tta.ClassificationTTAWrapper(model1, tta.aliases.five_crop_transform(500,500))"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T03:28:52.393670Z","iopub.status.busy":"2024-05-19T03:28:52.393274Z","iopub.status.idle":"2024-05-19T03:31:56.138262Z","shell.execute_reply":"2024-05-19T03:31:56.137370Z","shell.execute_reply.started":"2024-05-19T03:28:52.393640Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Model Evaluation -----\n","Test accuracy: 499 / 565 (88%)\n"]},{"data":{"text/plain":["88.31858407079646"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["test(tta_model, valid_loader) # validating the performance of the model with tta"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T03:32:14.800339Z","iopub.status.busy":"2024-05-19T03:32:14.799718Z","iopub.status.idle":"2024-05-19T03:32:14.804870Z","shell.execute_reply":"2024-05-19T03:32:14.803850Z","shell.execute_reply.started":"2024-05-19T03:32:14.800307Z"},"trusted":true},"outputs":[],"source":["tta_model2 = tta.ClassificationTTAWrapper(model1, tta.aliases.flip_transform()) # test time augmentation with flip transformation\n"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T03:36:57.873987Z","iopub.status.busy":"2024-05-19T03:36:57.873140Z","iopub.status.idle":"2024-05-19T03:40:16.840375Z","shell.execute_reply":"2024-05-19T03:40:16.839487Z","shell.execute_reply.started":"2024-05-19T03:36:57.873955Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Model Evaluation -----\n","Test accuracy: 502 / 565 (89%)\n"]},{"data":{"text/plain":["88.84955752212389"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["test(tta_model2, valid_loader) # Validating the performance of model2 with tta"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T09:30:20.179313Z","iopub.status.busy":"2024-05-19T09:30:20.178950Z","iopub.status.idle":"2024-05-19T09:30:23.544844Z","shell.execute_reply":"2024-05-19T09:30:23.543907Z","shell.execute_reply.started":"2024-05-19T09:30:20.179286Z"},"trusted":true},"outputs":[],"source":["loaded_model = torch.load('/kaggle/input/modelweight/get_resnext101_weighted.pth') # Loading the model weights"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T09:32:18.762636Z","iopub.status.busy":"2024-05-19T09:32:18.762233Z","iopub.status.idle":"2024-05-19T09:33:19.612374Z","shell.execute_reply":"2024-05-19T09:33:19.611239Z","shell.execute_reply.started":"2024-05-19T09:32:18.762604Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Model Evaluation -----\n","Test accuracy: 509 / 565 (90%)\n"]},{"data":{"text/plain":["90.08849557522124"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["test(loaded_model, valid_loader) #Validating performance using the model's weights"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T09:33:19.615535Z","iopub.status.busy":"2024-05-19T09:33:19.614392Z","iopub.status.idle":"2024-05-19T09:36:18.915110Z","shell.execute_reply":"2024-05-19T09:36:18.914083Z","shell.execute_reply.started":"2024-05-19T09:33:19.615499Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Model Evaluation -----\n","Test accuracy: 513 / 565 (91%)\n"]},{"data":{"text/plain":["90.79646017699115"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["tta_model = tta.ClassificationTTAWrapper(loaded_model, tta.aliases.five_crop_transform(484,484))\n","test(tta_model, valid_loader)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T09:36:18.916976Z","iopub.status.busy":"2024-05-19T09:36:18.916508Z","iopub.status.idle":"2024-05-19T09:39:41.210178Z","shell.execute_reply":"2024-05-19T09:39:41.209249Z","shell.execute_reply.started":"2024-05-19T09:36:18.916922Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Model Evaluation -----\n","Test accuracy: 514 / 565 (91%)\n"]},{"data":{"text/plain":["90.97345132743362"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["tta_model2 = tta.ClassificationTTAWrapper(loaded_model, tta.aliases.flip_transform()) #Second TTA Model with Flip Transform\n","test(tta_model2, valid_loader)\n"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T09:39:41.213234Z","iopub.status.busy":"2024-05-19T09:39:41.212909Z","iopub.status.idle":"2024-05-19T09:51:40.322491Z","shell.execute_reply":"2024-05-19T09:51:40.321490Z","shell.execute_reply.started":"2024-05-19T09:39:41.213206Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Model Evaluation -----\n","Test accuracy: 511 / 565 (90%)\n"]},{"data":{"text/plain":["90.4424778761062"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["tta_model = tta.ClassificationTTAWrapper(loaded_model, tta.aliases.five_crop_transform(500,500)) #Third TTA Model with Flip Transform\n","tta_model3 = tta.ClassificationTTAWrapper(tta_model, tta.aliases.flip_transform())\n","test(tta_model3, valid_loader)"]},{"cell_type":"markdown","metadata":{},"source":["to run"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T09:51:40.324500Z","iopub.status.busy":"2024-05-19T09:51:40.323791Z","iopub.status.idle":"2024-05-19T09:57:44.852479Z","shell.execute_reply":"2024-05-19T09:57:44.851409Z","shell.execute_reply.started":"2024-05-19T09:51:40.324468Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Model Evaluation -----\n","Test accuracy: 512 / 565 (91%)\n"]},{"data":{"text/plain":["90.61946902654867"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["tta_model4 = tta.ClassificationTTAWrapper(loaded_model, tta.aliases.ten_crop_transform(500,500)) # Fourth TTA Model with Flip Transform\n","test(tta_model4, valid_loader) "]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T09:57:44.854370Z","iopub.status.busy":"2024-05-19T09:57:44.854002Z","iopub.status.idle":"2024-05-19T11:56:11.669457Z","shell.execute_reply":"2024-05-19T11:56:11.668424Z","shell.execute_reply.started":"2024-05-19T09:57:44.854335Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Model Evaluation -----\n","Test accuracy: 514 / 565 (91%)\n"]},{"data":{"text/plain":["90.97345132743362"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["tta_model = tta.ClassificationTTAWrapper(loaded_model, tta.aliases.five_crop_transform(500,500)) #Fifth TTA Model with Flip Transform\n","tta_model5 = tta.ClassificationTTAWrapper(tta_model, tta.aliases.ten_crop_transform(500,500))\n","tta_model6 = tta.ClassificationTTAWrapper(tta_model5, tta.aliases.flip_transform())\n","test(tta_model6, valid_loader)"]},{"cell_type":"markdown","metadata":{},"source":["### **Predict function**"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T11:56:57.553864Z","iopub.status.busy":"2024-05-19T11:56:57.552980Z","iopub.status.idle":"2024-05-19T11:56:57.559859Z","shell.execute_reply":"2024-05-19T11:56:57.558815Z","shell.execute_reply.started":"2024-05-19T11:56:57.553829Z"},"trusted":true},"outputs":[],"source":["def predict(model, loader):\n","    model.eval()\n","    test_dataloader =  loader\n","    preds = []\n","    with torch.no_grad():\n","        for test_images, test_labels in tqdm(test_dataloader):\n","            test_images = test_images.to(device)\n","            test_labels = test_labels.to(device)\n","\n","            output = model(test_images)\n","\n","            _, predicted = torch.max(output, 1)\n","            preds.extend(predicted.cpu().data.numpy())\n","\n","\n","    return preds"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T11:57:03.609912Z","iopub.status.busy":"2024-05-19T11:57:03.608777Z","iopub.status.idle":"2024-05-19T13:17:25.695876Z","shell.execute_reply":"2024-05-19T13:17:25.694746Z","shell.execute_reply.started":"2024-05-19T11:57:03.609835Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 472/472 [1:20:22<00:00, 10.22s/it]\n"]}],"source":["preds6 = predict(tta_model2, test_loader) # making prediction using model 2 with tta"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T13:23:51.221336Z","iopub.status.busy":"2024-05-19T13:23:51.220444Z","iopub.status.idle":"2024-05-19T13:46:16.178921Z","shell.execute_reply":"2024-05-19T13:46:16.177896Z","shell.execute_reply.started":"2024-05-19T13:23:51.221300Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 472/472 [22:24<00:00,  2.85s/it]\n"]}],"source":["preds7 = predict(tta_model3, test_loader) # making prediction using model 3 with tta"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T13:48:05.675804Z","iopub.status.busy":"2024-05-19T13:48:05.675029Z","iopub.status.idle":"2024-05-19T13:48:05.684246Z","shell.execute_reply":"2024-05-19T13:48:05.683001Z","shell.execute_reply.started":"2024-05-19T13:48:05.675761Z"},"trusted":true},"outputs":[],"source":["name = [test_data.file_list[i][-1].split('/')[-1] for i in range(len(test_data.file_list))]"]},{"cell_type":"markdown","metadata":{},"source":["### **Preparing the submission file**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T13:49:23.776972Z","iopub.status.busy":"2024-05-19T13:49:23.776561Z","iopub.status.idle":"2024-05-19T13:49:23.805861Z","shell.execute_reply":"2024-05-19T13:49:23.804887Z","shell.execute_reply.started":"2024-05-19T13:49:23.776941Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Category</th>\n","      <th>Id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cgm</td>\n","      <td>test-img-1448.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>cmd</td>\n","      <td>test-img-768.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>cmd</td>\n","      <td>test-img-3481.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>cmd</td>\n","      <td>test-img-1475.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>cgm</td>\n","      <td>test-img-2498.jpg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Category                 Id\n","0      cgm  test-img-1448.jpg\n","1      cmd   test-img-768.jpg\n","2      cmd  test-img-3481.jpg\n","3      cmd  test-img-1475.jpg\n","4      cgm  test-img-2498.jpg"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["sample = pd.read_csv('/kaggle/input/ammi-2024-computer-vision/sample_submission_file.csv')\n","sample['Id'] = name\n","\n","# Mapping from class indices to class names\n","mapping = {0: 'cmd', 1: 'cbb', 2: 'cbsd', 3: 'healthy', 4: 'cgm'}\n","\n","# Convert predictions to class names\n","new_preds = [mapping[pred] for pred in preds7]\n","sample['Category'] = new_preds\n","\n","# Save the submission file\n","sample.to_csv('submission.csv', index=False)\n","sample.head()\n","print('submission file created successfully!')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":8400328,"sourceId":77142,"sourceType":"competition"},{"datasetId":5040451,"sourceId":8456882,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
