{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":77142,"databundleVersionId":8400328,"sourceType":"competition"},{"sourceId":8456882,"sourceType":"datasetVersion","datasetId":5040451}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Imports\nimport os\nimport sys\nimport glob\nimport torch\nimport torchvision\nimport pandas as pd\nfrom tqdm import tqdm\nfrom torchvision.models import alexnet\n\nimport numpy    as np\nimport datetime as dt\nimport torch.nn as nn\nimport ttach as tta\n\nimport torch.nn.functional as F\nimport matplotlib.pyplot   as plt\n\nfrom PIL               import Image\nfrom torch.utils.data  import Dataset\nfrom torch.autograd    import Variable\nfrom torch.optim       import lr_scheduler\n\nfrom torch.utils.data  import Dataset, DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torchvision       import transforms, datasets, models\nfrom os                import listdir, makedirs, getcwd, remove\nfrom os.path           import isfile, join, abspath, exists, isdir, expanduser\nimport gc\n# torch.cuda.empty_cache()\ngc.collect()\nimport os\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n\n%matplotlib inline","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":1.438614,"end_time":"2021-03-29T11:50:48.533762","exception":false,"start_time":"2021-03-29T11:50:47.095148","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-19T09:07:49.252330Z","iopub.execute_input":"2024-05-19T09:07:49.252724Z","iopub.status.idle":"2024-05-19T09:07:55.545913Z","shell.execute_reply.started":"2024-05-19T09:07:49.252690Z","shell.execute_reply":"2024-05-19T09:07:55.545083Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!pip install ttach","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_path = \"/kaggle/input/ammi-2024-computer-vision/\"\ntrain_path = join(data_path, \"train/train\")\ntest_path = join(data_path,\"test/test\")\nextraimage_path = join(data_path, \"extraimages/extraimages\")\n","metadata":{"papermill":{"duration":0.021142,"end_time":"2021-03-29T11:50:48.566314","exception":false,"start_time":"2021-03-29T11:50:48.545172","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-19T09:30:54.511996Z","iopub.execute_input":"2024-05-19T09:30:54.512400Z","iopub.status.idle":"2024-05-19T09:30:54.517557Z","shell.execute_reply.started":"2024-05-19T09:30:54.512371Z","shell.execute_reply":"2024-05-19T09:30:54.516535Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Transformations for both the training and testing data\nmean=[0.485, 0.456, 0.406]\nstd=[0.229, 0.224, 0.225]\n\n# Do data transforms here, Try many others\ntrain_transforms  = transforms.Compose([\n    transforms.Resize((580,580)),\n    #transforms.CenterCrop(448),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomVerticalFlip(p=0.5),\n    transforms.RandomRotation(degrees = 30),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    \n])\n\n\ntest_transforms = transforms.Compose([ transforms.Resize((580,580)),\n                                       #transforms.Resize(255),\n                                       #transforms.CenterCrop(448),\n                                       transforms.ToTensor(),\n                                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T09:30:54.868625Z","iopub.execute_input":"2024-05-19T09:30:54.869565Z","iopub.status.idle":"2024-05-19T09:30:54.877999Z","shell.execute_reply.started":"2024-05-19T09:30:54.869526Z","shell.execute_reply":"2024-05-19T09:30:54.876630Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class CassavaDataset(Dataset):\n    def __init__(self, path, transform=None):\n        self.classes = os.listdir(path)\n        self.path = [f\"{path}/{className}\" for className in self.classes]\n        self.file_list = [glob.glob(f\"{x}/*\") for x in self.path]\n        self.transform = transform\n\n        files = []\n        for i, className in enumerate(self.classes):\n            for fileName in self.file_list[i]:\n                files.append([i, className, fileName])\n        self.file_list = files\n        files = None\n\n    def __len__(self):\n        return len(self.file_list)\n\n    def __getitem__(self, idx):\n        fileName = self.file_list[idx][2]\n        classCategory = self.file_list[idx][0]\n        im = Image.open(fileName)\n        if self.transform:\n            im = self.transform(im)\n            \n        return im.view(3, 580, 580), classCategory","metadata":{"papermill":{"duration":0.02374,"end_time":"2021-03-29T11:50:48.633742","exception":false,"start_time":"2021-03-29T11:50:48.610002","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-19T09:30:55.358318Z","iopub.execute_input":"2024-05-19T09:30:55.359297Z","iopub.status.idle":"2024-05-19T09:30:55.369151Z","shell.execute_reply.started":"2024-05-19T09:30:55.359260Z","shell.execute_reply":"2024-05-19T09:30:55.368105Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_data = CassavaDataset(train_path, transform=train_transforms)\ntest_data = CassavaDataset(test_path, transform=test_transforms)","metadata":{"papermill":{"duration":0.614629,"end_time":"2021-03-29T11:50:49.259763","exception":false,"start_time":"2021-03-29T11:50:48.645134","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-19T09:30:55.707248Z","iopub.execute_input":"2024-05-19T09:30:55.707859Z","iopub.status.idle":"2024-05-19T09:30:56.528381Z","shell.execute_reply.started":"2024-05-19T09:30:55.707829Z","shell.execute_reply":"2024-05-19T09:30:56.527495Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"validation_split = .1\nshuffle_dataset = True\nrandom_seed= 42\n\n# Creating data indices for training and validation splits:\ndataset_size = len(train_data)\nindices = list(range(dataset_size))\nsplit = int(np.floor(validation_split * dataset_size))\n\nif shuffle_dataset :\n    np.random.seed(random_seed)\n    np.random.shuffle(indices)\n\ntrain_indices, val_indices = indices[split:], indices[:split]","metadata":{"papermill":{"duration":0.022198,"end_time":"2021-03-29T11:50:49.293623","exception":false,"start_time":"2021-03-29T11:50:49.271425","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-19T09:30:56.530276Z","iopub.execute_input":"2024-05-19T09:30:56.530966Z","iopub.status.idle":"2024-05-19T09:30:56.537782Z","shell.execute_reply.started":"2024-05-19T09:30:56.530910Z","shell.execute_reply":"2024-05-19T09:30:56.536909Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Creating PT data samplers and loaders:\ntrain_sampler = SubsetRandomSampler(train_indices)\nvalid_sampler = SubsetRandomSampler(val_indices)\n\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=8,\n                                             sampler=train_sampler)\nvalid_loader = torch.utils.data.DataLoader(train_data, batch_size=8,\n                                             sampler=valid_sampler)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=8)","metadata":{"papermill":{"duration":0.02193,"end_time":"2021-03-29T11:50:49.327221","exception":false,"start_time":"2021-03-29T11:50:49.305291","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-19T09:30:58.027373Z","iopub.execute_input":"2024-05-19T09:30:58.028194Z","iopub.status.idle":"2024-05-19T09:30:58.034731Z","shell.execute_reply.started":"2024-05-19T09:30:58.028155Z","shell.execute_reply":"2024-05-19T09:30:58.033697Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Device configuration\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"papermill":{"duration":0.021251,"end_time":"2021-03-29T11:50:49.36027","exception":false,"start_time":"2021-03-29T11:50:49.339019","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-19T09:31:03.311016Z","iopub.execute_input":"2024-05-19T09:31:03.311379Z","iopub.status.idle":"2024-05-19T09:31:03.316007Z","shell.execute_reply.started":"2024-05-19T09:31:03.311352Z","shell.execute_reply":"2024-05-19T09:31:03.314807Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(random_seed)  # Fix the random seed\n\nmodel = torchvision.models.resnext50_32x4d(pretrained=True)\n\n# Set the final linear layer to the number of classes of the problem\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 5)\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\nhypergrad_lr = 1e-9\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=3e-3)\nhypergrad_optimizer = torch.optim.Adam(model.parameters(), lr=hypergrad_lr)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T09:31:16.758030Z","iopub.execute_input":"2024-05-19T09:31:16.758422Z","iopub.status.idle":"2024-05-19T09:31:18.205293Z","shell.execute_reply.started":"2024-05-19T09:31:16.758391Z","shell.execute_reply":"2024-05-19T09:31:18.204427Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNeXt50_32X4D_Weights.IMAGENET1K_V1`. You can also use `weights=ResNeXt50_32X4D_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /root/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth\n100%|██████████| 95.8M/95.8M [00:00<00:00, 144MB/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the path to the folder containing the subfolders\npath = train_path\n\n# Get the list of subfolders\nsubfolders = [f.path for f in os.scandir(path) if f.is_dir()]\n\n# Create a list to store the number of images in each subfolder\nnum_images = []\n\n# Iterate over the subfolders and count the number of images\nfor subfolder in subfolders:\n    num_images.append(len(os.listdir(subfolder)))\n\n# Compute class weights\nclass_counts = num_images  # Number of samples per class\ntotal_samples = sum(class_counts)\nclass_weights = [total_samples / (len(class_counts) * count) for count in class_counts]\nclass_weights = torch.FloatTensor(class_weights).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T09:31:32.809259Z","iopub.execute_input":"2024-05-19T09:31:32.809634Z","iopub.status.idle":"2024-05-19T09:31:32.824459Z","shell.execute_reply.started":"2024-05-19T09:31:32.809597Z","shell.execute_reply":"2024-05-19T09:31:32.823451Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"num_classes = 5\nnum_epochs = 10\nlearning_rate = 1e-4\nhypergrad_lr = 1e-9\n\nmodel1 = torchvision.models.resnext101_64x4d(pretrained=True)\nmodel1.avgpool = nn.AdaptiveAvgPool2d((1, 1))\nnum_features = model1.fc.in_features\nmodel1.fc = nn.Linear(num_features, num_classes)\n\ncriterion = nn.CrossEntropyLoss(weight=class_weights)\n\noptimizer = torch.optim.Adam(model1.parameters(), lr=learning_rate)\nhypergrad_optimizer = torch.optim.Adam(model1.parameters(), lr=hypergrad_lr)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T09:31:32.826580Z","iopub.execute_input":"2024-05-19T09:31:32.826950Z","iopub.status.idle":"2024-05-19T09:31:39.580400Z","shell.execute_reply.started":"2024-05-19T09:31:32.826910Z","shell.execute_reply":"2024-05-19T09:31:39.579406Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNeXt101_64X4D_Weights.IMAGENET1K_V1`. You can also use `weights=ResNeXt101_64X4D_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnext101_64x4d-173b62eb.pth\" to /root/.cache/torch/hub/checkpoints/resnext101_64x4d-173b62eb.pth\n100%|██████████| 319M/319M [00:04<00:00, 76.0MB/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"def train(model, criterion, data_loader, valid_loader, optimizer, num_epochs):\n    # Move model to the device (CPU or GPU).\n    model = model.to(device)\n    \n    # Exponential moving average of the loss.\n    ema_loss = None\n    best_acc = 0\n\n    # Lists to store losses and accuracies.\n    losses = []\n    training_accuracies = []\n    validation_accuracies = []\n\n    print('----- Training Loop -----')\n    \n    # Loop over epochs.\n    for epoch in range(num_epochs):\n        # Make sure model is in training mode.\n        model.train()\n        correct = 0\n        \n        # Loop over data.\n        for batch_idx, (features, target) in enumerate(data_loader):\n            torch.cuda.empty_cache()\n            \n            # Forward pass.\n            output = model(features.to(device))\n            loss = criterion(output.to(device), target.to(device))\n            \n            # Backward pass.\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            # Compute the training accuracy\n            with torch.no_grad():\n                pred = output.argmax(dim=1, keepdim=True)\n                \n                # Count number of correct predictions.\n                correct += pred.cpu().eq(target.view_as(pred)).sum().item()\n            \n            # Exponential moving average of the loss.\n            if ema_loss is None:\n                ema_loss = loss.item()\n            else:\n                ema_loss += (loss.item() - ema_loss) * 0.01\n        \n        # Compute the training accuracy.\n        train_score = 100. * correct / len(data_loader.sampler)\n        \n        # Compute the validation accuracy.\n        valid_score = test(model, valid_loader)\n        \n        # Store the losses and accuracies.\n        losses.append(ema_loss)\n        training_accuracies.append(train_score)\n        validation_accuracies.append(valid_score)\n        \n        # Save the best model.\n        if valid_score > best_acc:\n            best_acc = valid_score\n            torch.save(model, 'get_resnext101_weighted.pth')\n        \n        # Print out progress at the end of epoch.\n        print(f'Epoch: {epoch} \\tLoss: {ema_loss:.12f} \\tTraining Accuracy: {train_score:.12f} \\tValidation Accuracy: {valid_score:.12f}')\n\n    return losses, training_accuracies, validation_accuracies\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test(model, data_loader):\n    # Make sure the model is in evaluation mode.\n    model.eval()\n    correct = 0\n    print('----- Model Evaluation -----')\n    \n    # We do not need to maintain intermediate activations while testing.\n    with torch.no_grad():\n        # Loop over test data.\n        for features, target in data_loader:\n            # Forward pass.\n            output = model(features.to(device))\n            \n            # Get the label corresponding to the highest predicted probability.\n            pred = output.argmax(dim=1, keepdim=True)\n            \n            # Count number of correct predictions.\n            correct += pred.cpu().eq(target.view_as(pred)).sum().item()\n    \n    # Print test accuracy.\n    percent = 100. * correct / len(valid_sampler)\n    print(f'Test accuracy: {correct} / {len(valid_sampler)} ({percent:.0f}%)')\n    \n    # torch.save(model.state_dict(), 'model.ckpt')\n    return percent\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T09:31:39.581650Z","iopub.execute_input":"2024-05-19T09:31:39.582001Z","iopub.status.idle":"2024-05-19T09:31:39.590535Z","shell.execute_reply.started":"2024-05-19T09:31:39.581973Z","shell.execute_reply":"2024-05-19T09:31:39.589347Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"num_epochs = 10\nlosses, training_accuracies, validation_accuracies = train(model1, criterion, train_loader, valid_loader, optimizer, num_epochs)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T23:07:31.875618Z","iopub.execute_input":"2024-05-18T23:07:31.876003Z","iopub.status.idle":"2024-05-19T03:16:25.204670Z","shell.execute_reply.started":"2024-05-18T23:07:31.875974Z","shell.execute_reply":"2024-05-19T03:16:25.203703Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"----- Training Loop -----\n----- Model Evaluation -----\nTest accuracy: 473 / 565 (84%)\nEpoch: 0 \tLoss: 0.578116055279 \tTraining Accuracy: 77.843252799057 \t Validation Accuracy: 83.716814159292\n----- Model Evaluation -----\nTest accuracy: 510 / 565 (90%)\nEpoch: 1 \tLoss: 0.446727400861 \tTraining Accuracy: 85.955607935573 \t Validation Accuracy: 90.265486725664\n----- Model Evaluation -----\nTest accuracy: 512 / 565 (91%)\nEpoch: 2 \tLoss: 0.344238200770 \tTraining Accuracy: 87.762718522884 \t Validation Accuracy: 90.619469026549\n----- Model Evaluation -----\nTest accuracy: 508 / 565 (90%)\nEpoch: 3 \tLoss: 0.310996923967 \tTraining Accuracy: 89.668041642114 \t Validation Accuracy: 89.911504424779\n----- Model Evaluation -----\nTest accuracy: 505 / 565 (89%)\nEpoch: 4 \tLoss: 0.299683268496 \tTraining Accuracy: 91.376939697505 \t Validation Accuracy: 89.380530973451\n----- Model Evaluation -----\nTest accuracy: 509 / 565 (90%)\nEpoch: 5 \tLoss: 0.243495238712 \tTraining Accuracy: 92.614417599686 \t Validation Accuracy: 90.088495575221\n----- Model Evaluation -----\nTest accuracy: 506 / 565 (90%)\nEpoch: 6 \tLoss: 0.195162089454 \tTraining Accuracy: 93.360832842271 \t Validation Accuracy: 89.557522123894\n----- Model Evaluation -----\nTest accuracy: 507 / 565 (90%)\nEpoch: 7 \tLoss: 0.159881586481 \tTraining Accuracy: 93.380475348654 \t Validation Accuracy: 89.734513274336\n----- Model Evaluation -----\nTest accuracy: 484 / 565 (86%)\nEpoch: 8 \tLoss: 0.164418969056 \tTraining Accuracy: 95.148300923198 \t Validation Accuracy: 85.663716814159\n----- Model Evaluation -----\nTest accuracy: 505 / 565 (89%)\nEpoch: 9 \tLoss: 0.114828447428 \tTraining Accuracy: 95.325083480652 \t Validation Accuracy: 89.380530973451\n","output_type":"stream"}]},{"cell_type":"code","source":"test(model1, valid_loader)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T03:19:40.125419Z","iopub.execute_input":"2024-05-19T03:19:40.126112Z","iopub.status.idle":"2024-05-19T03:20:36.156742Z","shell.execute_reply.started":"2024-05-19T03:19:40.126075Z","shell.execute_reply":"2024-05-19T03:20:36.155814Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"----- Model Evaluation -----\nTest accuracy: 498 / 565 (88%)\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"88.14159292035399"},"metadata":{}}]},{"cell_type":"code","source":"tta_model = tta.ClassificationTTAWrapper(model1, tta.aliases.five_crop_transform(500,500))","metadata":{"execution":{"iopub.status.busy":"2024-05-19T03:23:00.921694Z","iopub.execute_input":"2024-05-19T03:23:00.922555Z","iopub.status.idle":"2024-05-19T03:23:00.927202Z","shell.execute_reply.started":"2024-05-19T03:23:00.922487Z","shell.execute_reply":"2024-05-19T03:23:00.926153Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"test(tta_model, valid_loader)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T03:28:52.393274Z","iopub.execute_input":"2024-05-19T03:28:52.393670Z","iopub.status.idle":"2024-05-19T03:31:56.138262Z","shell.execute_reply.started":"2024-05-19T03:28:52.393640Z","shell.execute_reply":"2024-05-19T03:31:56.137370Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"----- Model Evaluation -----\nTest accuracy: 499 / 565 (88%)\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"88.31858407079646"},"metadata":{}}]},{"cell_type":"code","source":"tta_model2 = tta.ClassificationTTAWrapper(model1, tta.aliases.flip_transform())\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T03:32:14.799718Z","iopub.execute_input":"2024-05-19T03:32:14.800339Z","iopub.status.idle":"2024-05-19T03:32:14.804870Z","shell.execute_reply.started":"2024-05-19T03:32:14.800307Z","shell.execute_reply":"2024-05-19T03:32:14.803850Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"test(tta_model2, valid_loader)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T03:36:57.873140Z","iopub.execute_input":"2024-05-19T03:36:57.873987Z","iopub.status.idle":"2024-05-19T03:40:16.840375Z","shell.execute_reply.started":"2024-05-19T03:36:57.873955Z","shell.execute_reply":"2024-05-19T03:40:16.839487Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"----- Model Evaluation -----\nTest accuracy: 502 / 565 (89%)\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"88.84955752212389"},"metadata":{}}]},{"cell_type":"code","source":"loaded_model = torch.load('/kaggle/input/modelweight/get_resnext101_weighted.pth')","metadata":{"execution":{"iopub.status.busy":"2024-05-19T09:30:20.178950Z","iopub.execute_input":"2024-05-19T09:30:20.179313Z","iopub.status.idle":"2024-05-19T09:30:23.544844Z","shell.execute_reply.started":"2024-05-19T09:30:20.179286Z","shell.execute_reply":"2024-05-19T09:30:23.543907Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"test(loaded_mode, valid_loader)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T09:32:18.762233Z","iopub.execute_input":"2024-05-19T09:32:18.762636Z","iopub.status.idle":"2024-05-19T09:33:19.612374Z","shell.execute_reply.started":"2024-05-19T09:32:18.762604Z","shell.execute_reply":"2024-05-19T09:33:19.611239Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"----- Model Evaluation -----\nTest accuracy: 509 / 565 (90%)\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"90.08849557522124"},"metadata":{}}]},{"cell_type":"code","source":"tta_model = tta.ClassificationTTAWrapper(loaded_mode, tta.aliases.five_crop_transform(484,484))\ntest(tta_model, valid_loader)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T09:33:19.614392Z","iopub.execute_input":"2024-05-19T09:33:19.615535Z","iopub.status.idle":"2024-05-19T09:36:18.915110Z","shell.execute_reply.started":"2024-05-19T09:33:19.615499Z","shell.execute_reply":"2024-05-19T09:36:18.914083Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"----- Model Evaluation -----\nTest accuracy: 513 / 565 (91%)\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"90.79646017699115"},"metadata":{}}]},{"cell_type":"code","source":"tta_model2 = tta.ClassificationTTAWrapper(loaded_mode, tta.aliases.flip_transform())\ntest(tta_model2, valid_loader)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T09:36:18.916508Z","iopub.execute_input":"2024-05-19T09:36:18.916976Z","iopub.status.idle":"2024-05-19T09:39:41.210178Z","shell.execute_reply.started":"2024-05-19T09:36:18.916922Z","shell.execute_reply":"2024-05-19T09:39:41.209249Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"----- Model Evaluation -----\nTest accuracy: 514 / 565 (91%)\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"90.97345132743362"},"metadata":{}}]},{"cell_type":"code","source":"tta_model = tta.ClassificationTTAWrapper(loaded_mode, tta.aliases.five_crop_transform(500,500))\ntta_model3 = tta.ClassificationTTAWrapper(tta_model, tta.aliases.flip_transform())\ntest(tta_model3, valid_loader)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T09:39:41.212909Z","iopub.execute_input":"2024-05-19T09:39:41.213234Z","iopub.status.idle":"2024-05-19T09:51:40.322491Z","shell.execute_reply.started":"2024-05-19T09:39:41.213206Z","shell.execute_reply":"2024-05-19T09:51:40.321490Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"----- Model Evaluation -----\nTest accuracy: 511 / 565 (90%)\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"90.4424778761062"},"metadata":{}}]},{"cell_type":"markdown","source":"to run","metadata":{}},{"cell_type":"code","source":"tta_model4 = tta.ClassificationTTAWrapper(loaded_mode, tta.aliases.ten_crop_transform(500,500))\ntest(tta_model4, valid_loader)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T09:51:40.323791Z","iopub.execute_input":"2024-05-19T09:51:40.324500Z","iopub.status.idle":"2024-05-19T09:57:44.852479Z","shell.execute_reply.started":"2024-05-19T09:51:40.324468Z","shell.execute_reply":"2024-05-19T09:57:44.851409Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"----- Model Evaluation -----\nTest accuracy: 512 / 565 (91%)\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"90.61946902654867"},"metadata":{}}]},{"cell_type":"code","source":"tta_model = tta.ClassificationTTAWrapper(loaded_model, tta.aliases.five_crop_transform(500,500))\ntta_model5 = tta.ClassificationTTAWrapper(tta_model, tta.aliases.ten_crop_transform(500,500))\ntta_model6 = tta.ClassificationTTAWrapper(tta_model5, tta.aliases.flip_transform())\ntest(tta_model6, valid_loader)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T09:57:44.854002Z","iopub.execute_input":"2024-05-19T09:57:44.854370Z","iopub.status.idle":"2024-05-19T11:56:11.669457Z","shell.execute_reply.started":"2024-05-19T09:57:44.854335Z","shell.execute_reply":"2024-05-19T11:56:11.668424Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"----- Model Evaluation -----\nTest accuracy: 514 / 565 (91%)\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"90.97345132743362"},"metadata":{}}]},{"cell_type":"code","source":"def predict(model, loader):\n    model.eval()\n    test_dataloader =  loader\n    preds = []\n    with torch.no_grad():\n        for test_images, test_labels in tqdm(test_dataloader):\n            test_images = test_images.to(device)\n            test_labels = test_labels.to(device)\n\n            output = model(test_images)\n\n            _, predicted = torch.max(output, 1)\n            preds.extend(predicted.cpu().data.numpy())\n\n\n    return preds","metadata":{"execution":{"iopub.status.busy":"2024-05-19T11:56:57.552980Z","iopub.execute_input":"2024-05-19T11:56:57.553864Z","iopub.status.idle":"2024-05-19T11:56:57.559859Z","shell.execute_reply.started":"2024-05-19T11:56:57.553829Z","shell.execute_reply":"2024-05-19T11:56:57.558815Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"preds6 = predict(tta_model3, test_loader)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T11:57:03.608777Z","iopub.execute_input":"2024-05-19T11:57:03.609912Z","iopub.status.idle":"2024-05-19T13:17:25.695876Z","shell.execute_reply.started":"2024-05-19T11:57:03.609835Z","shell.execute_reply":"2024-05-19T13:17:25.694746Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"100%|██████████| 472/472 [1:20:22<00:00, 10.22s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"preds7 = predict(tta_model2, test_loader)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T13:23:51.220444Z","iopub.execute_input":"2024-05-19T13:23:51.221336Z","iopub.status.idle":"2024-05-19T13:46:16.178921Z","shell.execute_reply.started":"2024-05-19T13:23:51.221300Z","shell.execute_reply":"2024-05-19T13:46:16.177896Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stderr","text":"100%|██████████| 472/472 [22:24<00:00,  2.85s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"name = [test_data.file_list[i][-1].split('/')[-1] for i in range(len(test_data.file_list))]","metadata":{"execution":{"iopub.status.busy":"2024-05-19T13:48:05.675029Z","iopub.execute_input":"2024-05-19T13:48:05.675804Z","iopub.status.idle":"2024-05-19T13:48:05.684246Z","shell.execute_reply.started":"2024-05-19T13:48:05.675761Z","shell.execute_reply":"2024-05-19T13:48:05.683001Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"sample = pd.read_csv('/kaggle/input/ammi-2024-computer-vision/sample_submission_file.csv')\nsample['Id'] = name\n\n# Mapping from class indices to class names\nmapping = {0: 'cmd', 1: 'cbb', 2: 'cbsd', 3: 'healthy', 4: 'cgm'}\n\n# Convert predictions to class names\nnew_preds = [mapping[pred] for pred in preds7]\nsample['Category'] = new_preds\n\n# Save the submission file\nsample.to_csv('submission.csv', index=False)\nsample.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T13:49:23.776561Z","iopub.execute_input":"2024-05-19T13:49:23.776972Z","iopub.status.idle":"2024-05-19T13:49:23.805861Z","shell.execute_reply.started":"2024-05-19T13:49:23.776941Z","shell.execute_reply":"2024-05-19T13:49:23.804887Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"  Category                 Id\n0      cgm  test-img-1448.jpg\n1      cmd   test-img-768.jpg\n2      cmd  test-img-3481.jpg\n3      cmd  test-img-1475.jpg\n4      cgm  test-img-2498.jpg","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Category</th>\n      <th>Id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cgm</td>\n      <td>test-img-1448.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>cmd</td>\n      <td>test-img-768.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cmd</td>\n      <td>test-img-3481.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cmd</td>\n      <td>test-img-1475.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cgm</td>\n      <td>test-img-2498.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}